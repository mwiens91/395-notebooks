{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Callable\n",
    "from IPython.display import SVG, display\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of ballistic deposition induced films\n",
    "\n",
    "**PHYS 395 project 2; **\n",
    "**Matt Wiens - #301294492**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first command here sets the default figure size to be a bit larger than normal. The second command sets it so all figure output areas are expanded by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the format of Jupyter notebooks, I'm going to list my citations at the start of the notebook in this section. Usually citations would be at the end of a paper, but I find that due to the length of Jupyter notebooks, it's easier to scroll *up* through content you've already seen than to scroll *down* through lots of content you haven't yet seen.\n",
    "\n",
    "Citations will be listed by embedding the first three letters of the first author's last name in square brackets followed (optionally) by a page or page range (e.g., [Lan] corresponds to the book Landau was first author on). The citations are as follows:\n",
    "\n",
    "+ **[Ban]** Banerjee, K., Shamanna, J., & Ray, S. (2014). Surface morphology of a modified ballistic deposition model. Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics, 90(2), 22111.\n",
    "+ **[Bar]** Barabási, A.-L., & Stanley, H. E. (1995). Fractal Concepts in Surface Growth. Cambridge University Press. https://doi.org/10.1017/CBO9780511599798\n",
    "+ **[Lan]** Landau, R. H., Páez, M. J., & Bordeianu, C. C. (2015). Computational Physics: Problem Solving with Python (3rd ed.). Wiley-VCH.\n",
    "+ **[Li]** Li, J., Du, Q., & Sun, C. (2009). An improved box-counting method for image fractal dimension estimation. Pattern Recognition, 42(11), 2460–2469. https://doi.org/https://doi.org/10.1016/j.patcog.2009.03.001\n",
    "+ **[Man]** Mandelbrot, B. B. (1983). The Fractal Geometry of Nature. Henry Holt and Company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll look at how we can model and understand forms of particle aggregation using \"ballistic deposition\" models. To get a sense of what we mean by particle aggregation, imagine a manufacturing process in which particles are evaporated and form a film on some surface. Although the physics governing such a process is complicated, it turns out that we can accurately model how such films form with straightforward reasoning and simple mathematics [Bar, p.19]. The forms of particle aggregation we investigate in this notebook are important in the fabrication of nanomaterials and nanodevices, with many applications in medicine [Ban, p.1].\n",
    "\n",
    "What we will investigate in this notebook is the geometry and growth of films on cylindrical domains with cross-sectional \"rings\". To be specific with our geometry, we will take our domain $D$ to be given by\n",
    "\n",
    "\\begin{equation}\n",
    "    D = \\{(x, y): \\left\\Vert (x, y) \\right\\Vert_2 = r\\} \\times [0, +\\infty)\n",
    "\\end{equation}\n",
    "\n",
    "for some radius $r$, where $\\left\\Vert\\cdot\\right\\Vert_2$ is the $L^2$ norm. This is equivalent to a box with infinite height where we have periodic boundary conditions in the horizontal directions. To give a visual representation of such a domain, taking $r = 1$, consider the below plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot example domain\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "ts = np.linspace(0, 2 * np.pi, 64)\n",
    "zs = np.linspace(0, 10, 2)\n",
    "\n",
    "ts, zs = np.meshgrid(ts, zs)\n",
    "\n",
    "xs = np.cos(ts)\n",
    "ys = np.sin(ts)\n",
    "\n",
    "ax.plot_surface(xs, ys, zs,)\n",
    "\n",
    "# Cosmetics\n",
    "ax.set_xlabel(r\"$x$\")\n",
    "ax.set_ylabel(r\"$y$\")\n",
    "ax.set_zlabel(r\"$z$\");\n",
    "\n",
    "# Set informative perspective\n",
    "azim = -25.372434017595253\n",
    "elev = 54.22668240850038\n",
    "ax.view_init(azim=azim, elev=elev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will emphasize that the $z$ values have a minimum value of $0$, but $z$ goes to $+ \\infty$ in the positive direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will discuss fractal geometry and some of its features. We will then look at how we can simulate different forms of particle aggregation using ballistic deposition models. Finally, we will concern ourself the geometry and growth of these simulated particle aggregates and explore the connection the growth behaviour has to \"correlation length\" (this last part will be done after our analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fractals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly speaking, a fractal is a set for which the Hausdorff dimension strictly exceeds the topological dimension [Man, p.15] (more on this soon). The point of discussing fractals in a general setting is to introduce and demonstrate the concept of Hausdorff dimension (sometimes called \"fractal dimension\").\n",
    "\n",
    "We will see that the type of particle aggregation films we touched on in the introduction are actually fractals, and understanding fractal geometry is important in characterizing the geometry and growth of these films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hausdorff dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For brevity we will not give a formal treatment of Hausdorff dimension or topological dimension, and instead give an informal treatment. (Note that the formal treatment requires an early graduate-level understanding in mathematical analysis.) One can think of Hausdorff dimension as characterizing how much \"space\" a set fills up. For example, to determine the Hausdorff dimension for equilateral polygons with side length $L$ in $N$-dimensional space, we can relate the Hausdorff dimension $d_f$ to the $N$-dimensional volume $V$ with\n",
    "\n",
    "\\begin{equation}\n",
    "    V \\propto L^{d_f}\n",
    "    .\n",
    "\\end{equation}\n",
    "\n",
    "(This formula is a generalization of one presented in [Lan, p.384].) For example, a line segment with length $L$ in dimension $1$ has Hausdorff dimension $d_f = 1$ because the distance $l$ of the line trivially has the dependence\n",
    "\n",
    "\\begin{equation}\n",
    "    l = L^1\n",
    "    .\n",
    "\\end{equation}\n",
    "\n",
    "In dimension $2$, squares and equilateral triangles with side length $L$ have Hausdorff dimension $d_f = 2$ because the areas $A$ of these objects have the dependence\n",
    "\n",
    "\\begin{equation}\n",
    "    A \\propto L^2\n",
    "    .\n",
    "\\end{equation}\n",
    "\n",
    "The generalization of this is that no equilateral polygons are fractal, since their Hausdorff dimension are equal to their topological dimension. (Note also that circles and cubes too have this property, by considering the characteristic length as the radius $r$, instead of the side length $L$ for equilateral polygons.) In our analysis, we will see demonstrate fractal objects whose Hausdorff dimension exceeds their topological dimension (although bear in mind that pretty much everything in this notebook is fractal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ballistic deposition models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will describe the two models of ballistic deposition we will analyze in this notebook. For more details on either of these models see [Lan, pp.390-391, pp.395-396]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ballistic deposition model (BD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first ballistic deposition model we consider we will simply call the *ballistic deposition model* (hereafter abbreviated as BD). In the BD model, we will model particles as being two dimensional squares with unit side length. Then, we will partition the x-y portion of our domain $D$ (the cross-sectional ring) into $N$ equally spaced \"sites\" with width equal to the particle width. Viewing this in three dimensions, each site will form a column extending from $z = 0$ to $z = +\\infty$. We will define the height of each column as the highest $z$ value which a particle occupies in that column (if there is no such particle then the height is $0$).\n",
    "\n",
    "The model works as follows:\n",
    "\n",
    "1. we randomly drop a particle from $z = +\\infty$ into a column $c_1$ that has height $h_{c_1}$\n",
    "2. the particle \"falls\" down the column $c_1$ and\n",
    "\n",
    "    + (a) if the particle encounters another particle in an adjacent column $c_2$ on its descent, with the height of the other particle being at $h_{c_2} > h_{c_1}$, it \"sticks\" to that particle and gets deposited in column $c_1$ at height $h_{c_2}$;\n",
    "    + (b) otherwise, the particle sticks to the highest particle in its column, so it gets deposited in column $c_1$ at height $h_{c_1} + 1$.\n",
    "    \n",
    "3. repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated deposition model (CBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second ballistic deposition model we will look at is the *correlated ballistic deposition model* (hereafter abbreviated CBD). The CBD model is similar to the BD model except that after steps 1 and 2 in the BD model, the particle is deposited (or discarded) with a probability that depends on its distance $d$ from the most recent previously deposited particle. Let $P(d)$ denote this probability. Then, we have the following steps:\n",
    "\n",
    "1. we randomly drop a particle from $z = +\\infty$ into a column $c_1$ that has height $h_{c_1}$\n",
    "2. the particle \"falls\" down the column $c_1$ and\n",
    "\n",
    "    + (a) if the particle encounters another particle in an adjacent column $c_2$ on its descent, with the height of the other particle being at $h_{c_2} > h_{c_1}$, it \"sticks\" to that particle and *potentially* gets deposited in column $c_1$ at height $h_{c_2}$;\n",
    "    + (b) otherwise, the particle sticks to the highest particle in its column, and * potentially* gets deposited in column $c_1$ at height $h_{c_1} + 1$.\n",
    "    \n",
    "3. sample the probability distribution $\\text{Bernoulli}(P(d))$: if the sampled value is $1$, deposit the particle (otherwise discard it)\n",
    "4. repeat\n",
    "\n",
    "This model is useful in modeling particle interactions when particles are dropped together (although not at exactly the same time). For a \"Coulomb-type\" attraction, we can take\n",
    "\n",
    "\\begin{equation}\n",
    "    P(d) := \\min \\left\\{\\frac{c}{d^2}, 1 \\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "where $c$ is a scaling constant.\n",
    "\n",
    "As a finer point on calculating distances, since our domain $D$ is cylindrical, we take the distance $d$ to be the shortest distance between the two points *along* the cylinder (hence we do not calculate the distance as *through* the cylinder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing the geometry and growth of the particle aggregate films generated by the BD and CBD models, we will restrict ourselves to analyzing the surface of the film.\n",
    "\n",
    "Recall that in each ballistic deposition model, we have $N$ sites, and each of these sites has an associated column. We will denote $h(i, t)$ to be the height of the $i$th column (corresponding to the $i$th site) at time $t$. (Recall that the height of a column is the highest $z$ value that a particle occupies in that column, or $0$, if there are no particles in the column.)\n",
    "\n",
    "We will be interested in two quantities. The first is the *mean height* of the surface, $\\bar{h}(t)$, defined by\n",
    "\n",
    "\\begin{equation}\n",
    "    \\bar{h}(t) := \\frac{1}{N} \\sum_{i = 1}^N h(i, t)\n",
    "    .\n",
    "\\end{equation}\n",
    "\n",
    "The second is the *interface width* $w(t)$, which is the root mean square fluctuation in height defined by\n",
    "\n",
    "\\begin{equation}\n",
    "    w(t) := \\sqrt{\\frac{1}{N} \\sum_{i = 1}^N \\left( h(i, t) - \\bar{h}(t) \\right)^2}\n",
    "    .\n",
    "\\end{equation}\n",
    "\n",
    "The interface width characterizes the \"roughness\" of the surface [Bar, p.22]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've covered the necessary theory, let's get into the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrating fractal behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at general fractal behaviour. The point of looking at fractals in a general sense is to demonstrate the Hausdorff dimension and seeing how fractals can arise from simple algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sierpiński triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example we'll consider is the Sierpiński triangle. Classically, you can generate this object by starting with any equilateral triangle and subdividing this triangle it into four smaller equilateral triangles of the same size (this subdivision is unique). After removing the \"central\" triangle, apply a similar subdivision to each of the remaining triangles, and repeat this process ad infinitum. Wikipedia has a good illustration of the first few steps of the procedure as shown below (the image was created by Wikipedia users Saperoud and Wereon). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_url = \"https://upload.wikimedia.org/wikipedia/commons/0/05/Sierpinski_triangle_evolution.svg\"\n",
    "display(SVG(url=svg_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sierpiński triangle has topological dimension $1$ (one way to think about this without getting into the mathematical definition of topological dimension is to recognize that it has no area). However, its Hausdorff dimension $d_f$ is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    d_f = \\frac{\\log3}{\\log2} \\approx 1.585\n",
    "    .\n",
    "\\end{equation}\n",
    "\n",
    "One way to solve for $d_f$ is by recognizing that if we double the starting side length $L$ of the equilateral triangle then we create $2$ additional copies of the object and so by our above formula of the Hausdorff dimension we require\n",
    "\n",
    "\\begin{equation}\n",
    "    3 L^{d_f} = (2 L)^{d_f}\n",
    "    ,\n",
    "\\end{equation}\n",
    "\n",
    "which, after solving for $d_f$, gives us the desired result. Hence we have shown the Hausdorff dimension to be strictly greater than the topological dimension, and so the Sierpiński triangle is a fractal that \"fills more space\" than a one dimensional object but less than a two dimensional object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Hausdorff dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to compute fractal dimension by approximating fractals computationally through formulas called \"chaos games\". Two such examples are shown below. The Sierpiński triangle can be approximated by following the choas game in [Lan, p.384] and the dimension can be estimated using so-called \"box-counting\" methods (see [Li] or [Lan, pp.392-393]). For the second example shown below, the three dimensional Barnsley fern (generated by the chaos game in [Lan, pp.387-389]) has no explicit mathematical construction and the Hausdorff dimension can only be estimated computationally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sierpiński triangle (chaos game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertices of the equilateral triangle\n",
    "vertices = np.array([[0.0, 0.0], [0.5, 1.0], [1.0, 0.0]])\n",
    "\n",
    "# Pick a random point within the triangle to start\n",
    "s, t = np.sort(np.random.random(2))\n",
    "init_point = np.array(\n",
    "    [\n",
    "        s * vertices[0, 0] + (t - s) * vertices[1, 0] + (1 - t) * vertices[2, 0],\n",
    "        s * vertices[0, 1] + (t - s) * vertices[1, 1] + (1 - t) * vertices[2, 1],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an array with all the points we'll compute\n",
    "num_points = 25000\n",
    "\n",
    "points = np.zeros((num_points, 2))\n",
    "points[0, :] = init_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the simulation\n",
    "for i in range(1, num_points):\n",
    "    r = np.random.randint(3)\n",
    "    \n",
    "    points[i, :] = 0.5 * (points[i - 1, :] + vertices[r, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulation results\n",
    "_, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "ax.scatter(x=points[:, 0], y=points[:, 1], s=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barnsley fern (chaos game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up array to store data\n",
    "num_points = 25000\n",
    "\n",
    "points = np.zeros((num_points, 3))\n",
    "\n",
    "# Initial point is fixed\n",
    "points[0, :] = np.array([0.5, 0.0, -0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup mode transformation matrices\n",
    "mode_1_mat = np.array([[0.0, 0.0, 0.0], [0.0, 0.18, 0.0], [0.0, 0.0, 0.0]])\n",
    "mode_2_mat = np.array([[0.85, 0.0, 0.0], [0.0, 0.85, 0.1], [0.0, -0.1, 0.85]])\n",
    "mode_3_mat = np.array([[0.2, -0.2, 0.0], [0.2, 0.2, 0.0], [0.0, 0.0, 0.3]])\n",
    "mode_4_mat = np.array([[-0.2, 0.2, 0.0], [0.2, 0.2, 0.0], [0.0, 0.0, 0.3]])\n",
    "\n",
    "# Constants to add after each matrix product\n",
    "mode_1_consts = np.array([0.0, 0.0, 0.0])\n",
    "mode_2_consts = np.array([0.0, 1.6, 0.0])\n",
    "mode_3_consts = np.array([0.0, 0.8, 0.0])\n",
    "mode_4_consts = np.array([0.0, 0.8, 0.0])\n",
    "\n",
    "# Bundle up all the matrices and constants\n",
    "mode_mats = [mode_1_mat, mode_2_mat, mode_3_mat, mode_4_mat]\n",
    "mode_consts = [mode_1_consts, mode_2_consts, mode_3_consts, mode_4_consts]\n",
    "\n",
    "# Probabilities of obtaining each mode\n",
    "mode_probabilities = np.array([0.1, 0.6, 0.15, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the simulation\n",
    "for i in range(1, num_points):\n",
    "    mode = np.random.choice([0, 1, 2, 3], p=mode_probabilities)\n",
    "\n",
    "    points[i, :] = mode_mats[mode] @ points[i - 1, :] + mode_consts[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulation results\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# The ordering of the x,y,z points were chosen to get the best\n",
    "# default view.\n",
    "ax.scatter(ys=points[:, 0], zs=points[:, 1], xs=points[:, 2], s=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ballistic deposition simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having touched on the Hausdorff dimension, we will now move on to ballistic deposition. Here we will show plots of what is generated by the BD and CBD models discussed in the theory section above. Although we are simulating on our cylindrical-like domain $D$, note that using a \"box\" domain gives very similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ballistic deposition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll simulate the (uncorrelated) ballistic deposition model using $300$ sites and simulating the deposition of $25000$ particles. Note that having $300$ sites means the radius $r$ for our domain $D$ is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    r \\approx \\frac{300}{2 \\pi} \\approx 47.7\n",
    "\\end{equation}\n",
    "\n",
    "in units of particle box length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of particles to simulate\n",
    "num_particles = 25000\n",
    "\n",
    "# Number sites on ring substrate\n",
    "num_substrate_sites = 300\n",
    "\n",
    "# Array of heights at each substrate site\n",
    "heights = np.zeros(num_substrate_sites)\n",
    "\n",
    "# Array of particle positions (once deposited)\n",
    "points = np.zeros((num_particles, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to deal with boundary conditions\n",
    "left_site = lambda site: site - 1\n",
    "right_site = lambda site: (site + 1) % num_substrate_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the simulation\n",
    "for i in range(num_particles):\n",
    "    site = np.random.randint(num_substrate_sites)\n",
    "\n",
    "    # Determine the maximum height of the neighbouring sites\n",
    "    neighbour_max_height = np.array(\n",
    "        [heights[s] for s in [left_site(site), right_site(site)]]\n",
    "    ).max()\n",
    "\n",
    "    # Determine where to place the particle\n",
    "    if heights[site] >= neighbour_max_height:\n",
    "        heights[site] += 1\n",
    "    else:\n",
    "        heights[site] = neighbour_max_height\n",
    "\n",
    "    points[i, :] = np.array([site, heights[site]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulation results\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(x=points[:, 0], y=points[:, 1], s=1.5)\n",
    "\n",
    "# Cosmetics\n",
    "ax.set_xlim([0, num_substrate_sites])\n",
    "ax.set_ylim(ymin=0)\n",
    "\n",
    "ax.set_xlabel(\"substrate site\")\n",
    "ax.set_ylabel(\"height\")\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated ballistic deposition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll simulate the correlated ballistic deposition model (again) using $300$ sites and simulating the deposition of $25000$ particles. We will take the probability $P(d)$ that a particle is deposited based on its distance from the previously deposited particle to be a Coulomb-like attraction given by\n",
    "\n",
    "\\begin{equation}\n",
    "    P(d) := \\min \\left\\{ \\frac{c}{d^2}, 1 \\right\\}\n",
    "    ,\n",
    "\\end{equation}\n",
    "\n",
    "where we have taken the scaling constant $c = 5$ in the simulation below.\n",
    "\n",
    "Note that this simulation can potentially take much longer to run than the previous simulation, since we will have many more iterations than the number of particles we simulate (due to many of them being discarded by our correlation constraint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of particles to simulate\n",
    "num_particles = 25000\n",
    "\n",
    "# Number sites on ring substrate\n",
    "num_substrate_sites = 300\n",
    "\n",
    "# Array of heights at each substrate site\n",
    "heights = np.zeros(num_substrate_sites)\n",
    "\n",
    "# Array of particle positions (once deposited)\n",
    "points = np.zeros((num_particles, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to deal with boundary conditions\n",
    "left_site = lambda site: site - 1\n",
    "right_site = lambda site: (site + 1) % num_substrate_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the simulation\n",
    "i = 0\n",
    "\n",
    "while i < num_particles:\n",
    "    site = np.random.randint(num_substrate_sites)\n",
    "\n",
    "    # Determine the maximum height of the neighbouring sites\n",
    "    neighbour_max_height = np.array(\n",
    "        [heights[s] for s in [left_site(site), right_site(site)]]\n",
    "    ).max()\n",
    "\n",
    "    # Determine where to place the particle\n",
    "    if heights[site] >= neighbour_max_height:\n",
    "        candidate_height = heights[site] + 1\n",
    "    else:\n",
    "        candidate_height = neighbour_max_height\n",
    "\n",
    "    candidate_point = np.array([site, candidate_height])\n",
    "\n",
    "    # Determine whether to deposit the particle\n",
    "    # based on its distance from the previous particle\n",
    "    if i == 0:\n",
    "        # First particle always gets placed\n",
    "        pass\n",
    "    else:\n",
    "        # Calculate distance from previous particle. We need\n",
    "        # to be careful with periodic boundary conditions here.\n",
    "        dx = abs(points[i - 1, 0] - site)\n",
    "        mindx = min(dx, num_substrate_sites - dx,)\n",
    "        dsquared = mindx ** 2 + (points[i - 1, 1] - candidate_height) ** 2\n",
    "\n",
    "        if np.random.random() < 5 / dsquared:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Deposit the particle\n",
    "    heights[site] = candidate_height\n",
    "    points[i, :] = candidate_point\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot simulation results\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(x=points[:, 0], y=points[:, 1], s=1.5)\n",
    "\n",
    "# Cosmetics\n",
    "ax.set_xlim([0, num_substrate_sites])\n",
    "ax.set_ylim(ymin=0)\n",
    "\n",
    "ax.set_xlabel(\"substrate site\")\n",
    "ax.set_ylabel(\"height\")\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ballistic deposition interface width growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen what the simulations for ballistic depositions generate, let's look at how the interface width grows with time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a general ballistic deposition function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're going to be computing a lot of data, we'll define a function which takes in\n",
    "\n",
    "+ the number of sites $N$\n",
    "+ the number of particles to simulate\n",
    "+ (optionally) a function $P(d)$ to determine the correlation-dependent probability in the CBD model\n",
    "\n",
    "and returns an array with the $i$th index giving the interface width $w(i)$ after the $i$th particle has been deposited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_mean(\n",
    "    num_sites: int, old_mean: float, old_value: int, new_value: int\n",
    ") -> float:\n",
    "    \"\"\"Calculates new mean given a change in one value.\"\"\"\n",
    "    return old_mean + (new_value - old_value) / num_sites\n",
    "\n",
    "\n",
    "def calculate_interface_width(\n",
    "    num_sites: int, heights: np.ndarray, mean_height: float\n",
    ") -> float:\n",
    "    \"\"\"Calculates the interface width.\"\"\"\n",
    "    return math.sqrt(1 / num_sites * np.sum((heights - mean_height) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bd_interface_widths(\n",
    "    num_sites: int, num_particles: int, prob_fn: Callable[[float], float] = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Simulates a BD model and returns an array of interface widths.\"\"\"\n",
    "    # Functions to deal with boundary conditions\n",
    "    left_site = lambda site: site - 1\n",
    "    right_site = lambda site: (site + 1) % num_sites\n",
    "\n",
    "    # Array of heights at each site\n",
    "    heights = np.zeros(num_sites)\n",
    "\n",
    "    # Current mean height\n",
    "    mean_height = 0\n",
    "\n",
    "    # Array of interface widths to return\n",
    "    interface_widths = np.zeros(num_particles)\n",
    "\n",
    "    # Perform the simulation\n",
    "    i = 0\n",
    "\n",
    "    # Last particle position (if running CBD)\n",
    "    last_position = None\n",
    "\n",
    "    while i < num_particles:\n",
    "        site = np.random.randint(num_sites)\n",
    "\n",
    "        # Determine the maximum height of the neighbouring sites\n",
    "        neighbour_max_height = np.array(\n",
    "            [heights[s] for s in [left_site(site), right_site(site)]]\n",
    "        ).max()\n",
    "\n",
    "        # Determine where to place the particle\n",
    "        if heights[site] >= neighbour_max_height:\n",
    "            candidate_height = heights[site] + 1\n",
    "        else:\n",
    "            candidate_height = neighbour_max_height\n",
    "\n",
    "        candidate_point = np.array([site, candidate_height])\n",
    "\n",
    "        # Determine whether to deposit the particle\n",
    "        # based on its distance from the previous particle\n",
    "        # (if running CBD)\n",
    "        if prob_fn is not None:\n",
    "            if last_position is None:\n",
    "                # First particle always gets placed\n",
    "                pass\n",
    "            else:\n",
    "                # Calculate distance from previous particle. We need\n",
    "                # to be careful with periodic boundary conditions here.\n",
    "                dx = abs(last_position[0] - site)\n",
    "                mindx = min(dx, num_substrate_sites - dx,)\n",
    "\n",
    "                d = math.sqrt(mindx ** 2 + (last_position[1] - candidate_height) ** 2)\n",
    "\n",
    "                if np.random.random() < prob_fn(d):\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            last_position = np.array([site, candidate_height])\n",
    "\n",
    "        # Calculate new mean height\n",
    "        mean_height = calculate_new_mean(\n",
    "            num_sites, mean_height, heights[site], candidate_height\n",
    "        )\n",
    "\n",
    "        # Increase the height of the column\n",
    "        heights[site] = candidate_height\n",
    "\n",
    "        # Calculate the interface width\n",
    "        interface_widths[i] = calculate_interface_width(num_sites, heights, mean_height)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return interface_widths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BD interface growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at how the interface width in the BD model grows with time. First we'll generate some data, depositing $10^5$ particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sites = 200\n",
    "num_particles = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_data = bd_interface_widths(num_sites = num_sites, num_particles = num_particles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the interface width versus time (each unit of time is a deposited particle) on a log-log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(x=range(num_particles), y=bd_data, s=0.5)\n",
    "\n",
    "# Set log log scaling and proper view\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_xlim([10, num_particles])\n",
    "ax.set_ylim([0.1, 10])\n",
    "\n",
    "# Cosmetics\n",
    "ax.set_xlabel(r\"$t$\")\n",
    "ax.set_ylabel(r\"$w(t)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you should be seeing is that the interface width eventually saturates!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you *don't* see that in the above plot that was generated, try running it again. Due to the relatively low number of sites, randomness can play a role in the data that is generated (even then if you use enough particles you should still see the saturation eventually, even if it's noisy); increasing sites will mitigate this, but that also means you would need to increase the number of particles as well to reach the saturation point (more on this soon). There's a performance trade-off for \"better quality\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are two regimes: initially the interface width $w(t)$ increases as a power of time (since it appears linear on a log-log plot), that is, for some exponent $\\beta$ we have that initially (say for $t < t_x$ where we will call $t_x$ the \"crossover time\")\n",
    "\n",
    "\\begin{equation}\n",
    "    w(t) \\propto t^\\beta \\quad \\text{for } t < t_x.\n",
    "\\end{equation}\n",
    "\n",
    "However, for $t > t_x$ the interface width saturates at some value $w_{sat}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does saturation happen? It's unintuitive that a random system like this would saturate (at least it is for me). Before answering this question, let's examine what effect the number of sites plays. (Note: the following code block might take awhile to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sites to test\n",
    "num_sites_list = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "num_particles = 100000\n",
    "\n",
    "bd_big_data = np.ndarray((len(num_sites_list), num_particles))\n",
    "\n",
    "for idx, num_sites in enumerate(num_sites_list):\n",
    "    bd_big_data[idx, :] = bd_interface_widths(\n",
    "        num_sites=num_sites, num_particles=num_particles\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "for data in bd_big_data:\n",
    "    ax.scatter(x=range(num_particles), y=data, s=0.1)\n",
    "\n",
    "# Set log log scaling and proper view\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_xlim([10, num_particles])\n",
    "ax.set_ylim([0.1, 10])\n",
    "\n",
    "# Cosmetics\n",
    "ax.set_xlabel(r\"$t$\")\n",
    "ax.set_ylabel(r\"$w(t)$\")\n",
    "\n",
    "ax.legend([\"%d sites\" % num_sites for num_sites in num_sites_list], markerscale=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now admittedly, this plot is hard to look at. To get another view, let's plot all of them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(3, 2, figsize=(17, 17), sharex=True, sharey=True)\n",
    "\n",
    "for ax, data, num_sites in zip(axes.flatten(), bd_big_data, num_sites_list):\n",
    "    ax.scatter(x=range(num_particles), y=data, s=0.1)\n",
    "\n",
    "    # Set log log scaling and proper view\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    ax.set_xlim([10, num_particles])\n",
    "    ax.set_ylim([0.1, 10])\n",
    "\n",
    "    # Cosmetics\n",
    "    ax.set_xlabel(r\"$t$\")\n",
    "    ax.set_ylabel(r\"$w(t)$\")\n",
    "    ax.set_title(\"%d sites\" % num_sites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a clear finite size effect. As the number of sites $N$ increases, the system takes longer to saturate (i.e., the crossover time $t_x$ increases), and the interface width saturation value $w_{sat}$ increases. It is not clear whether the exponent $\\beta$ characterizing the growth regime is affected from these plots; it would appear not to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that both $t_x$ and and $w_{sat}$ increase linearly with the number of sites $N$ on a log-log scale (see [Bar p.23]), and hence there exist exponents $\\alpha$ and $\\gamma$ such that\n",
    "\n",
    "\\begin{align}\n",
    "    w_{sat}(N) &\\propto N^\\alpha, \\\\\n",
    "    t_x(N) &\\propto N^\\gamma\n",
    "    .\n",
    "\\end{align}\n",
    "\n",
    "Noting that $N$ is simply the circumference of our cylindrical domain, we can immediately identify $\\alpha$ as the Hausdorff dimension of our interface width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a bit more to the story than what I've written above; for example, it turns out that\n",
    "\n",
    "\\begin{equation}\n",
    "    \\gamma = \\frac{\\alpha}{\\beta}\n",
    "    ;\n",
    "\\end{equation}\n",
    "\n",
    "for the interest reader, see [Bar pp.23-25]. One observation I will emphasize is that saturation is a finite size effect! According to the above equations for $w_{sat}(N)$ and $t_x(N)$ above, if we take the number of sites $N$ (or equivalently, the radius of our cylindrical domain) to go to infinity, then the interface width (the roughness of the surface) will grow indefinitely and never saturate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get back to a question I asked (but didn't answer) above: why does the system saturate in the first place. It turns out that sites on the surface are correlated. Each new particle that gets deposited due to a neighbouring site at greater height is essentially transmitting information about its neighbour to the *other* neighbour. Hence in small systems, sites will equilibriate faster and the surface will be less rough because information about local surface heights is transmitted faster. In larger systems, information takes longer to transmit. This \"transmission time\" is known as the correlation length, and it should be intuitive that for our system, the correlation length is proportional to the number of sites $N$.\n",
    "\n",
    "(Note that this idea of correlation length is a new concept for me, so I might not be explaining/understanding it that well. See [Bar, pp.25-27] for likely a better explanation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBD interface growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll step back and look at how the interface width in the CBD model grows with time. Here we'll only plot $4 \\cdot 10^3$ particles since this simulation takes significantly longer than the BD simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sites = 200\n",
    "num_particles = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_data = bd_interface_widths(\n",
    "    num_sites=num_sites, num_particles=num_particles, prob_fn=lambda d: 5 / d ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the interface width versus time (each unit of time is a deposited particle) on a log-log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(x=range(num_particles), y=cbd_data, s=0.5)\n",
    "\n",
    "# Set log log scaling and proper view\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_xlim([10, num_particles])\n",
    "ax.set_ylim([0.1, 10])\n",
    "\n",
    "# Cosmetics\n",
    "ax.set_xlabel(r\"$t$\")\n",
    "ax.set_ylabel(r\"$w(t)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that, predictably the interface width grows much more rapidly as a function of time than in the BD model (if this is not intuitive then refer back to the simulation plots for the CBD model above). Due to the computational intensity of this model, unfortunately I don't have the computational power to see what happens with large numbers of particles (think $10^6$). This is an open question for me really: will the system saturate in the same way the BD model does? I want to say that it depends on the correlation probability function $P(d)$. One can imagine setting $P(d)$ to be such that the newly particle essentially needs to be adjacent or on top of the previously deposited particle. Surely such a system would never saturate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we've investigated how ballistic deposition induced films and their growth can be characterized. In doing so, we've discussed concepts that relate to ballistic deposition such as Hausdorff dimension, finite size effects, and correlation length. However, there is much we haven't yet investigated, and that I'm still interested in. I'll break the \"future directions\" part into three topics I'm most interested in.\n",
    "\n",
    "When discussing the growth of the interface width in the BD model we saw that we had\n",
    "\n",
    "\\begin{align}\n",
    "    w(N, t) &\\propto t^\\beta \\qquad \\text{for } t < t_x, \\\\\n",
    "    w_{sat}(N) &\\propto N^\\alpha, \\\\\n",
    "    t_x(N) &\\propto N^\\gamma\n",
    "    .\n",
    "\\end{align}\n",
    "\n",
    "The data we had to work with was extremely noisy (due to the randomness of the simulation and relatively small number of sites). How can we fit those parameters to noisy data in a way that essentially cancels out the randomness? Perhaps we can smooth the data by averaging across multiple simulations? As an alternative, certainly by hand we can draw on the log-log plots and determine the exponents easily enough (we just need to draw lines over our data); is there a computational equivalent to this by-hand drawing?\n",
    "\n",
    "Secondly, when discussing the Hausdorff dimension earlier on, I mentioned that we can approximate it computationally using box-counting methods on fractals generated computationally. As an alternative to fitting the curves we plotted above, can we determine the exponent $\\alpha$ using these box-counting methods based on our computed points on the ballistic deposition films?\n",
    "\n",
    "Lastly, I really want to know what happens in the CBD model with regard to saturation. I think the key here is to find a way to simplify the algorithm to make it less computationally intensive, so, as a starting point, we can produce plots equivalent to what we did in the BD model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
