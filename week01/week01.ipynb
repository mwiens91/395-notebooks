{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHYS 395 - week 1\n",
    "\n",
    "**Matt Wiens - #301294492**\n",
    "\n",
    "This notebook will be organized similarly to the lab script, with major headings corresponding to the headings on the lab script.\n",
    "\n",
    "*The TA's name (Ignacio) will be shortened to \"IC\" whenever used.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set default plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python and the Jupyter environment\n",
    "\n",
    "With permission from IC, I've used the import style I'm used to instead of `%pylab notebook` (I like knowing what's in my namespace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print \"hello world\"\n",
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print pi with numbers of significant digits\n",
    "for i in [3, 8, 16]:\n",
    "    # IC: is there a cleaner way of formatting than what I've done here?\n",
    "    print(\"%.*f\" % (i, math.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Lennard-Jones potential\n",
    "\n",
    "The Lennard-Jones potential models interactions between pairs of neutral atoms or molecules. One equation for the Lennard-Jones potential $V_{\\text{LJ}}$ is\n",
    "\n",
    "\\begin{equation}\n",
    "    V_{\\text{LJ}} =\n",
    "        4 \\epsilon\n",
    "        \\left(\n",
    "            \\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6 \n",
    "        \\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\epsilon$ is the depth of the potential well, $\\sigma$ is the finite distance at which the inter-particle potential is zero, and $r$ is the distance between the particles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we express the distance between particles $r$ in terms of $\\sigma$ we can remove the $\\sigma$ parameter above.\n",
    "\n",
    "The first function below gives the LJ potential with $r$ and $\\sigma$ having the same units of length. The second function gives the LJ potential where $r$ is expressed in terms of $\\sigma$ (and hence does not require $\\sigma$ as an argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lj_potential_1(r: float, sigma: float, eps: float) -> float:\n",
    "    \"\"\"Computes the L-J potential.\n",
    "\n",
    "    r and sigma must be expressed in the same units of length.\n",
    "    \"\"\"\n",
    "    l = sigma / r\n",
    "\n",
    "    return 4 * eps * (l ** 12 - l ** 6)\n",
    "\n",
    "\n",
    "def lj_potential_2(r: float, eps: float) -> float:\n",
    "    \"\"\"Computes the L-J potential.\n",
    "\n",
    "    r must be expressed in terms of sigma.\n",
    "    \"\"\"\n",
    "    return lj_potential_1(r, 1, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the LJ potential\n",
    "\n",
    "First we will plot with $\\epsilon = 1$, then we will plot with multiple values of $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note: these values are expressed in terms of sigma\n",
    "r_vals = np.linspace(0.99, 15, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(r_vals, [lj_potential_2(r, 1) for r in r_vals]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the same shape as the classic potential curve taught in undergraduate physics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll plot with different values of $\\epsilon$. We'll keep using the same $r$ values as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eps_vals = range(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot\n",
    "for eps in eps_vals:\n",
    "    plt.plot(r_vals, [lj_potential_2(r, eps) for r in r_vals])\n",
    "\n",
    "# Legend\n",
    "ax.legend([r\"$\\epsilon$ = %d\" % eps for eps in eps_vals])\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$r$/$\\sigma$\")\n",
    "ax.set_ylabel(r\"V/$\\epsilon$\")\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(\"ljplot.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase $\\epsilon$ we see that the potential energy gets more negative at its lowest point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data provided has many snapshots of a droid's position (in metres). Snapshots were taken every second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in CSV to a dataframe\n",
    "relative_file_path = \"droid_traj.csv\"\n",
    "\n",
    "df = pd.read_csv(relative_file_path, names=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data loaded in is contained in a Pandas dataframe which has 250 rows and 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_rows, num_cols = df.shape\n",
    "\n",
    "print(\"rows: %d; cols: %d\" % (num_rows, num_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the trajectory given to us by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"x\", y=\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path length\n",
    "\n",
    "We will now calculate the path length traversed for each second. The path lengths will be stored in an array, where the indices correspond to the time (0-indexed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_lengths = np.zeros(num_rows)\n",
    "\n",
    "for t in range(1, num_rows):\n",
    "    path_lengths[t] = path_lengths[t - 1] + np.linalg.norm(df.iloc[t] - df.iloc[t - 1])\n",
    "\n",
    "# Also create a function for this, as an alternative interface\n",
    "def s(t: int) -> int:\n",
    "    \"\"\"Returns path length traversed at time t (0-indexed).\"\"\"\n",
    "    return path_lengths[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total path length is approximately 129m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total path length: %.2fm\" % path_lengths[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed\n",
    "\n",
    "We will now estimate the speed of the droid at each second. Since the time step between each data point is a second, we can simply take the difference of the path lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speeds = np.zeros(num_rows - 1)\n",
    "\n",
    "for t in range(num_rows - 1):\n",
    "    speeds[t] = s(t + 1) - s(t)\n",
    "\n",
    "# Again we'll define a function for this\n",
    "def v(t: int) -> int:\n",
    "    \"\"\"Returns estimated speed at time t (0-indexed).\"\"\"\n",
    "    return speeds[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tangential acceleration\n",
    "\n",
    "We will now estimate the tangential acceleration of the droid at each second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accels = np.zeros(num_rows - 2)\n",
    "\n",
    "for t in range(num_rows - 2):\n",
    "    accels[t] = v(t + 1) - v(t)\n",
    "\n",
    "\n",
    "def a(t: int) -> int:\n",
    "    \"\"\"Returns estimated acceleration at time t (0-indexed).\"\"\"\n",
    "    return accels[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting path length, speed, and tangential acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the path length, speed, and tangential acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axes\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1)\n",
    "fig.set_size_inches(10, 15)\n",
    "fig.subplots_adjust(hspace=0.25)\n",
    "\n",
    "# Add titles\n",
    "ax1.title.set_text(\"path length\")\n",
    "ax2.title.set_text(\"speed\")\n",
    "ax3.title.set_text(\"tangential acceleration\")\n",
    "\n",
    "# Add labels\n",
    "for ax in (ax1, ax2, ax3):\n",
    "    ax.set_xlabel(r\"$t$ (s)\")\n",
    "    ax.xaxis.set_label_coords(0.5, -0.05)\n",
    "\n",
    "ax1.set_ylabel(\"m\")\n",
    "ax2.set_ylabel(\"m/s\")\n",
    "ax3.set_ylabel(r\"m/$\\mathrm{s}^2$\")\n",
    "\n",
    "# Plot\n",
    "ts = list(range(num_rows))\n",
    "ax1.plot(ts, path_lengths)\n",
    "ax2.plot(ts[:-1], speeds)\n",
    "ax3.plot(ts[:-2], accels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1 homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Trajectory coloured by tangential acceleration\n",
    "\n",
    "Now we will plot the droid's trajectory with the points coloured by tangential acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the dataset\n",
    "df_trimmed = df.drop(df.tail(2).index)\n",
    "\n",
    "# Add in acceleration values\n",
    "df_trimmed[\"accel\"] = accels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(x=df_trimmed[\"x\"], y=df_trimmed[\"y\"], c=df_trimmed[\"accel\"], cmap=\"viridis\")\n",
    "\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random numbers\n",
    "\n",
    "First we'll define a function that calculates the next element of a pseudo-random number sequence generated by a linear congruential generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_element_lcg(x: int, a: int, c: int, m: int) -> int:\n",
    "    \"\"\"Calculates the next element of an lcg rng sequence.\"\"\"\n",
    "    return (a * x + c) % m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using $x_0 = 1$, $a = 12$, $c = 0$, and $m = 143$, we will generate a sequence of 13 pseudo-random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience functions\n",
    "print_num = lambda x, i: print(\"elem %02d: %d\" % (i, x))\n",
    "get_next_num = lambda x: next_element_lcg(x, 12, 0, 143)\n",
    "\n",
    "# Compute the sequence and print it\n",
    "x = 1\n",
    "\n",
    "print_num(x, 0)\n",
    "\n",
    "for i in range(1, 14):\n",
    "    x = get_next_num(x)\n",
    "    print_num(x, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence repeats with a period of 2! This is because with our choice of parameters,\n",
    "\n",
    "\\begin{align}\n",
    "    (12 \\cdot 1) \\mod 143 &= 12, \\\\ \\\\\n",
    "    (12 \\cdot 12) \\mod 143 &= 144 \\mod 143 \\\\\n",
    "        &= 1.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"Randu\" generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at the \"Randu\" generator, which sets $a = 65539$, $c = 0$, and $m = 2^{31}$. First, we'll generate a 1000 numbers using this generator, then we'll plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next_num = lambda x: next_element_lcg(x, 65539, 0, 2 ** 31)\n",
    "\n",
    "# We'll start with a non-zero seed\n",
    "seed = 17\n",
    "\n",
    "# Now generate the numbers\n",
    "randu_nums = np.zeros(1000)\n",
    "randu_nums[0] = seed\n",
    "\n",
    "for i in range(1, 1000):\n",
    "    randu_nums[i] = get_next_num(randu_nums[i - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot we'll look at is a scatter plot of $x_{i + 1}$ against $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.scatter(x=randu_nums[:-1], y=randu_nums[1:])\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$x_i$\")\n",
    "ax.set_ylabel(r\"$x_{i + 1}$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this relatively small set of numbers generated, everything seems fine. The points on the plot appear to uniformly cover the plane, and I can't make out any correlated bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll generate a 3D plot showing triplets $(x_{i + 2}, x_{i + 1}, x_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "ax.scatter3D(xs=randu_nums[:-2], ys=randu_nums[1:-1], zs=randu_nums[2:])\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$x_i$\")\n",
    "ax.set_ylabel(r\"$x_{i + 1}$\")\n",
    "ax.set_zlabel(r\"$x_{i + 2}$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rotate the plot change the first cell `%matplotlib inline` to `%matplotlib notebook` at the beginning of this notebook and rerun the entire notebook. However, a \"pre-rotated\" version of the above plot is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot again at a different angle\n",
    "plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "ax.scatter3D(xs=randu_nums[:-2], ys=randu_nums[1:-1], zs=randu_nums[2:])\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$x_i$\")\n",
    "ax.set_ylabel(r\"$x_{i + 1}$\")\n",
    "ax.set_zlabel(r\"$x_{i + 2}$\")\n",
    "\n",
    "# Set the view\n",
    "elev = -85.21335807050122\n",
    "azim = -45.36774193548365\n",
    "\n",
    "ax.view_init(azim=azim, elev=elev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By rotating the plot we can see clear evidence of banding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating uniform random numbers and timing calculations in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will generate 10,000 random numbers by calling the `random.random` function 10,000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start = timer()\n",
    "\n",
    "# Generate the numbers\n",
    "nums = [random.random() for _ in range(10 ** 4)]\n",
    "\n",
    "# End timer and print time\n",
    "end = timer()\n",
    "\n",
    "print(\"time: %fs\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll generate 10,000 random numbers using a single call using NumPy's `random.random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start = timer()\n",
    "\n",
    "# Generate the numbers\n",
    "nums = np.random.random(10 ** 4)\n",
    "\n",
    "# End timer and print time\n",
    "end = timer()\n",
    "\n",
    "print(\"time: %fs\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a single call is around an order of magnitude faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot these numbers on a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "plt.figure()\n",
    "\n",
    "plt.hist(nums, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the numbers appear to be random. Note that if we used many more bins in the above histogram, two things would happen: (1) It would take forever to render; (2) It would highlight insignificant differences in the distribution of numbers that comes from using a small sample size (10,000, in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability distributions: discrete and continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radioactive decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $P(t)$ be the probability density that a particle decay has not happened up to some time $t$. We are given that the probability that a decay happens in time $dt$ is given by $r \\, dt$.\n",
    "\n",
    "Given that a particle has not decayed at some time $t$, the change in probability that it has not decayed for the next time step is given by\n",
    "\n",
    "\\begin{align}\n",
    "    \\frac{dP}{dt} &= - \\text{(probability particle decays now)}\n",
    "                        \\cdot \\text{(probability particle hasn't decayed until now)} \\\\\n",
    "                  &= - r P.\n",
    "\\end{align}\n",
    "\n",
    "Solving for $P$, we obtain\n",
    "\n",
    "\\begin{equation}\n",
    "    P(t) = c e^{-r t}\n",
    "\\end{equation}\n",
    "\n",
    "for some constant $c$.\n",
    "\n",
    "To determine what the constant $c$ is, we use the fact that $P(t)$ is a probability distribution:\n",
    "\n",
    "\\begin{align}\n",
    "    \\int_0^\\infty P(t) dt &= \\int_0^\\infty c e^{-r t} dt \\\\\n",
    "                          &= c \\int_0^\\infty e^{-r t} dt \\\\\n",
    "                          &= c \\left(- \\frac{1}{r} \\right) (0 - 1) \\\\\n",
    "                          &= \\frac{c}{r} \\\\\n",
    "                          &= 1 \\qquad \\text{(P is prob. dist.)}.\n",
    "\\end{align}\n",
    "\n",
    "This implies that $c = r$ and hence\n",
    "\n",
    "\\begin{equation}\n",
    "    P(t) = r e^{-r t}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to simulate 10,000 decay times using the above equation. We will choose $dt = 1$ and $r = 0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_decay(r: float, dt: float) -> float:\n",
    "    \"\"\"Simulate decay time for a particle.\"\"\"\n",
    "    rdt = r * dt\n",
    "    \n",
    "    t = 0\n",
    "\n",
    "    while True:\n",
    "        if random.random() < rdt:\n",
    "            return t\n",
    "\n",
    "        t += dt\n",
    "\n",
    "\n",
    "r = 0.01\n",
    "dt = 1\n",
    "\n",
    "# Simulate 10,000 times\n",
    "decay_times = np.array([simulate_decay(r, dt) for _ in range(10 ** 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll plot a plain histogram of the decay times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.hist(decay_times, bins=30)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$t$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the same histogram, but normalized, and with the probability distribution $P(t)$ superimposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.hist(decay_times, bins=30, density=True)\n",
    "\n",
    "# Plot the \"true\" probability density\n",
    "ts = np.linspace(0, 1000, 500)\n",
    "plt.plot(ts, r * np.exp(-r * ts), linewidth=3)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$t$\")\n",
    "ax.set_ylabel(r\"prob\")\n",
    "\n",
    "# Legend\n",
    "ax.legend([\"data\", r\"$P(t)$\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is strong agreement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating decay (again)\n",
    "\n",
    "Here we'll do all of the above simulation with a new value of $dt = 0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 10,000 times. Note that with this value of dt,\n",
    "# computing the decay times may take some time!\n",
    "r = 0.01\n",
    "dt = 0.01\n",
    "\n",
    "decay_times = np.array([simulate_decay(r, dt) for _ in range(10 ** 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.hist(decay_times, bins=30)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$t$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Probability density plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.hist(decay_times, bins=30, density=True)\n",
    "\n",
    "# Plot the \"true\" probability density\n",
    "ts = np.linspace(0, 1000, 500)\n",
    "plt.plot(ts, r * np.exp(-r * ts), linewidth=3)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$t$\")\n",
    "ax.set_ylabel(r\"prob\")\n",
    "\n",
    "# Legend\n",
    "ax.legend([\"data\", r\"$P(t)$\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this number of bins, it's hard to see a difference in this simulation compared to the last one. However, if we increase the number of bins, we see that lowering $dt$ increases the agreement of the data with the probability density curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating decay with NumPy\n",
    "\n",
    "We'll keep $r = 0.01$ as in the previous simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NumPy exponential distribution\n",
    "decay_times = np.random.exponential(scale=1 / r, size=10 ** 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.hist(decay_times, bins=30)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$t$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability density plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.hist(decay_times, bins=30, density=True)\n",
    "\n",
    "# Plot the \"true\" probability density\n",
    "ts = np.linspace(0, 1000, 500)\n",
    "plt.plot(ts, r * np.exp(-r * ts), linewidth=3)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$t$\")\n",
    "ax.set_ylabel(r\"prob\")\n",
    "\n",
    "# Legend\n",
    "ax.legend([\"data\", r\"$P(t)$\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that using the NumPy distribution directly not only agrees with our earlier results, but is faster, and more \"accurate\" (in the sense that we are taking the $dt \\to 0$ limit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will simulate a number of 1D random walks with step size 1 for different number of steps $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(n: int, a: int = 1) -> int:\n",
    "    \"\"\"Calculates end-to-end distance of 1D random walk.\"\"\"\n",
    "    return np.sum(np.random.choice(a=[a, -a], size=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N values\n",
    "n_vals = [5, 25, 50, 100, 200, 400, 750, 1000]\n",
    "\n",
    "# Create an array to store results\n",
    "num_ns = len(n_vals)\n",
    "num_trials = 10 ** 4\n",
    "\n",
    "data = np.zeros((num_ns, num_trials))\n",
    "\n",
    "# Simulate the walks\n",
    "for row, n in enumerate(n_vals):\n",
    "    for col in range(num_trials):\n",
    "        data[row][col] = r(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll compute the mean end-to-end distances for each $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the means\n",
    "mean_rs = [np.mean(data[row]) for row in range(num_ns)]\n",
    "\n",
    "# Print the means\n",
    "for idx, n in enumerate(n_vals):\n",
    "    print(\"N = %04d;\\tr(N) = %+f\" % (n, mean_rs[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was probably anticipated, the mean end-to-end distance is close to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the mean squared distances (MSDs) for each $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSDs\n",
    "mean_sqrd_rs = [np.mean(np.square(data[row])) for row in range(num_ns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the MSDs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.scatter(x=n_vals, y=mean_sqrd_rs)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$N$\")\n",
    "ax.set_ylabel(\"MSD\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSDs appear to be linear with $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might the above MSD plot look like if all steps were taken in the same direction? Well, the distance for each walk would always be $N$, so in this special case we would have\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle r(N)^2 \\rangle = \\langle N^2 \\rangle = N^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical derivations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the means we have\n",
    "\n",
    "\\begin{align}\n",
    "    \\langle r(N) \\rangle\n",
    "        &= \\sum_{i = 1}^N \\langle dx_i \\rangle \\\\\n",
    "        &= \\sum_{i = 1}^N \\left( \\frac{1}{2} a + \\frac{1}{2} (-a) \\right) \\\\\n",
    "        &= \\sum_{i = 1}^N 0 \\\\\n",
    "        &= 0.\n",
    "\\end{align}\n",
    "\n",
    "For the MSDs we have\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle r(N)^2 \\rangle\n",
    "        = \\sum_{i = 1}^N \\sum_{j = 1}^N \\langle dx_i \\cdot dx_j \\rangle.\n",
    "\\end{equation}\n",
    "\n",
    "Note that in the above sum, when $i = j$, we have\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle dx_i \\cdot dx_j \\rangle\n",
    "        = \\left( \\frac{1}{2} a^2 + \\frac{1}{2} (-a)^2 \\right)\n",
    "        = a^2;\n",
    "\\end{equation}\n",
    "\n",
    "and for $i \\neq j$,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle dx_i \\cdot dx_j \\rangle\n",
    "        = \\left(\n",
    "            \\frac{1}{4} a^2\n",
    "            + \\frac{1}{4} (-a) a\n",
    "            + \\frac{1}{4} a (-a)\n",
    "            + \\frac{1}{4} (-a)^2\n",
    "           \\right)\n",
    "        = 0.\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle dx_i \\cdot dx_j \\rangle = a^2 \\delta_{ij},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\delta_{ij}$ is the Kronecker delta function.\n",
    "\n",
    "Returning to the MSD derivation, we have\n",
    "\n",
    "\\begin{align}\n",
    "    \\langle r(N)^2 \\rangle\n",
    "        &= \\sum_{i = 1}^N \\sum_{j = 1}^N \\langle dx_i \\cdot dx_j \\rangle \\\\\n",
    "        &= \\sum_{i = 1}^N a^2 \\\\\n",
    "        &= N a^2.\n",
    "\\end{align}\n",
    "\n",
    "This agrees with the MSD scatter plot we produced above which suggested a linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms from simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick three Ns from our data to focus on\n",
    "n1_idx = 3\n",
    "n2_idx = 4\n",
    "n3_idx = 5\n",
    "\n",
    "n1, n2, n3 = n_vals[n1_idx], n_vals[n2_idx], n_vals[n3_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axes\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1)\n",
    "fig.set_size_inches(10, 15)\n",
    "fig.subplots_adjust(hspace=0.25)\n",
    "\n",
    "# Add titles\n",
    "for ax, n in zip((ax1, ax2, ax3), (n1, n2, n3)):\n",
    "    ax.title.set_text(r\"$N$ = %d\" % n)\n",
    "\n",
    "# Add labels\n",
    "for ax in (ax1, ax2, ax3):\n",
    "    ax.set_xlabel(\"distance\")\n",
    "    ax.set_ylabel(\"proportion\")\n",
    "\n",
    "# Plot\n",
    "n_bins = 9\n",
    "\n",
    "for ax, n_idx in zip((ax1, ax2, ax3), (n1_idx, n2_idx, n3_idx)):\n",
    "    ax.hist(data[n_idx], bins=n_bins, density=True)\n",
    "\n",
    "# Make limits the same\n",
    "for ax in (ax1, ax2, ax3):\n",
    "    ax.set_xlim(-80, 80)\n",
    "    ax.set_ylim(0, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms appear to be approaching a normal distribution. Theoretically as we increase $N$, the number of steps, the histograms should get closer to the normal distribution.\n",
    "\n",
    "We can now identify the mean $\\langle r(N) \\rangle$ as the mean of the normal distribution and $\\langle r(N)^2 \\rangle$ as the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2 homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overlaying Gaussians on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data we have, let's overlay a Gaussian on our plots using the the mean and variance discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axes\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1)\n",
    "fig.set_size_inches(10, 15)\n",
    "fig.subplots_adjust(hspace=0.25)\n",
    "\n",
    "# Add titles\n",
    "for ax, n in zip((ax1, ax2, ax3), (n1, n2, n3)):\n",
    "    ax.title.set_text(r\"$N$ = %d\" % n)\n",
    "\n",
    "# Add labels\n",
    "for ax in (ax1, ax2, ax3):\n",
    "    ax.set_xlabel(\"distance\")\n",
    "    ax.set_ylabel(\"proportion\")\n",
    "\n",
    "# Plot histograms\n",
    "n_bins = 9\n",
    "\n",
    "for ax, n_idx in zip((ax1, ax2, ax3), (n1_idx, n2_idx, n3_idx)):\n",
    "    ax.hist(data[n_idx], bins=n_bins, density=True)\n",
    "\n",
    "# Plot Gaussians\n",
    "xs = np.linspace(-80, 80, 500)\n",
    "\n",
    "for ax, n in zip((ax1, ax2, ax3), (n1, n2, n3)):\n",
    "    ax.plot(xs, stats.norm.pdf(xs, 0, math.sqrt(n)), linewidth=3)\n",
    "\n",
    "\n",
    "# Add legends\n",
    "for ax in (ax1, ax2, ax3):\n",
    "    ax.legend([r\"$\\mathcal{N}(0, N)$\", \"data\"])\n",
    "\n",
    "# Make limits the same\n",
    "for ax in (ax1, ax2, ax3):\n",
    "    ax.set_xlim(-80, 80)\n",
    "    ax.set_ylim(0, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in the above plots that there is good agreement between our data and the Gaussian distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulating a 2D random walk on a square lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will simulate a 2D random walk, where each step can be four directions (with equal weight): up, down, left, right. Here we will be interested in the means $\\langle r(N) \\rangle$ and mean squared end-to-end distance $\\langle r(N)^2 \\rangle$.\n",
    "\n",
    "In contrast to the 1D random walk—where $r(N)$ was signed (i.e., could be positive or negative)—for the 2D random walk $r(N)$ will be the magnitude of the final displacement vector. This simplication is justified since the walk is isotropic, and hence we will have radial symmetry (in the limit of large $N$ at least)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's simulate the walk for a number of different $N$ values, each with multiple trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_2d(n: int, a: int = 1) -> float:\n",
    "    \"\"\"Calculates end-to-end distance of 2D random walk.\"\"\"\n",
    "    return np.absolute(np.sum(np.random.choice(a=[a, -a, a * 1j, -a * 1j], size=n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N values\n",
    "n_vals = [5, 25, 50, 100, 200, 400, 750, 1000]\n",
    "\n",
    "# Create an array to store results\n",
    "num_ns = len(n_vals)\n",
    "num_trials = 10 ** 4\n",
    "\n",
    "data = np.zeros((num_ns, num_trials))\n",
    "\n",
    "# Simulate the walks\n",
    "for row, n in enumerate(n_vals):\n",
    "    for col in range(num_trials):\n",
    "        data[row][col] = r_2d(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the means and MSDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the means\n",
    "mean_rs = [np.mean(data[row]) for row in range(num_ns)]\n",
    "\n",
    "# Calculate MSDs\n",
    "mean_sqrd_rs = [np.mean(np.square(data[row])) for row in range(num_ns)]\n",
    "\n",
    "# Plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.scatter(x=n_vals, y=mean_rs)\n",
    "plt.scatter(x=n_vals, y=mean_sqrd_rs)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$N$\")\n",
    "\n",
    "# Legend\n",
    "ax.legend([r\"$\\langle r(N) \\rangle$\", r\"$\\langle r(N)^2 \\rangle$\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are nearly identical to the results we had for the 1D random walk!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
