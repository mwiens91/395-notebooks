{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHYS 395 - week 2\n",
    "\n",
    "**Matt Wiens - #301294492**\n",
    "\n",
    "This notebook will be organized similarly to the lab script, with major headings corresponding to the headings on the lab script.\n",
    "\n",
    "*The TA's name (Ignacio) will be shortened to \"IC\" whenever used.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set default plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical error homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Truncation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncation error is the error involved in approximating an infinite sum by a finite sum. For example, the truncation error involved in approximating $e^x$ to the first three terms of its Taylor series is\n",
    "\n",
    "\\begin{equation}\n",
    "    \\left| e^x - \\left(1 + x + \\frac{x^2}{2}\\right)\\right|\n",
    "    .\n",
    "\\end{equation}\n",
    "\n",
    "For numerical integration, truncation error comes in to play because we are approximating an integral (an infinite sum) by a finite sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rounding error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given any algorithm which produces a result, rounding error is the difference between producing that result using exact arithmetic and producing the result using finite-precision, rounded arithmetic (floating point arithmetic). On a computer, a number called \"machine epsilon\" gives you the upper bound of the relative error that occurs in floating point arithmetic due to rounding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demonstrating floating point arithmetic error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(7 / 3 - 4 / 3 - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above in exact arithmetic should be $0$. But due to error in floating point arithmetic it is instead a non-zero small number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical integration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal in this section will be to investigate how we can approximate integrals according to different \"rules\".    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple rule\n",
    "\n",
    "Consider some function $f$ defined on an interval $[a, b]$. A simple rule to approximate the integral of $f$ over this interval is to take $N + 1$ evenly spaced points along the interval $\\{x_1, x_2, \\ldots, x_{N + 1}\\}$ and then add up the area of the rectangles induced by these points (see the picture in the lab script). Note that we always have $x_1 = a$ and $x_N = b$. This gives us the following approximation:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\int_a^b f(x) dx \\approx \\sum_{i = 1}^N f(x_i) h\n",
    "    ,\n",
    "\\end{equation}\n",
    "\n",
    "where $h$ is the width of each rectangle given by\n",
    "\n",
    "\\begin{equation}\n",
    "    h = \\frac{b - a}{N}\n",
    "    .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_left_reimann(y: np.ndarray, h: float):\n",
    "    \"\"\"Approximates an integral using the left Reimann sum.\"\"\"\n",
    "    return np.sum(y * h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will approximate the integral of $\\sin(x)$ over $[0, \\frac{\\pi}{2}]$ using logarithmically spaced values of $N$. We will plot the absolute error as a function of the bin width $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a number of N values and the corresponding h values\n",
    "num_ns = 50\n",
    "\n",
    "# We need to be a little careful since we want the N values to\n",
    "# be logarithmically space, but we also require that each N is an integer.\n",
    "n_vals = np.round(np.logspace(1, 6, num_ns)).astype(int)\n",
    "h_vals = np.pi / (2 * n_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we plot the absolute errors, note that\n",
    "\n",
    "\\begin{equation}\n",
    "    \\int_0^{\\frac{\\pi}{2}} \\sin(x) dx = 1\n",
    "    .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each N value calculate the absolute error\n",
    "errors = np.zeros(num_ns)\n",
    "\n",
    "for idx, n in enumerate(n_vals):\n",
    "    xs = np.linspace(0, np.pi / 2, n + 1)\n",
    "    ys = np.sin(xs)\n",
    "\n",
    "    errors[idx] = abs(1 - integrate_left_reimann(ys, np.pi / (2 * n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.loglog(h_vals, errors, \"o\")\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$h$\")\n",
    "ax.set_ylabel(\"abs error\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a linear relationship in the log-log plot. This means that the error E is related to $h$ through some relationship of the form\n",
    "\n",
    "\\begin{equation}\n",
    "    E = A h^\\alpha\n",
    "    .\n",
    "\\end{equation}\n",
    "\n",
    "This is because a linear relationship in log-log can be expressed as\n",
    "\n",
    "\\begin{align}\n",
    "    &\\log E = \\alpha \\log h + \\log A \\\\\n",
    "    &\\iff \\log E = \\log \\left( A h^\\alpha \\right) \\\\\n",
    "    &\\iff E = A h^\\alpha\n",
    "    .\n",
    "\\end{align}\n",
    "\n",
    "By inspection, I would guess that $\\alpha = 1$ and $A = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to fit the log values we obtained to a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the linear coefficients for the loglog relationship\n",
    "coeffs = np.polyfit(x=np.log(h_vals), y=np.log(errors), deg=1)\n",
    "\n",
    "# Translate to A and h\n",
    "print(\"A = %.2f\" % np.exp(coeffs[1]))\n",
    "print(\"alpha = %.2f\" % coeffs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My guess for $\\alpha$ was correct, but the value for $A$ I guessed was not quite right (it's difficult to make out on the above plot what $A$ should be with any precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the coefficients we calculated, we can estimate that to get an error less than or equal to $10^{-8}$ we would need a width of \n",
    "\n",
    "\\begin{align}\n",
    "    h &= \\left( \\frac{E}{A} \\right)^{\\frac{1}{\\alpha}} \\\\\n",
    "      &\\approx \\frac{10^{-8}}{0.49} \\\\\n",
    "      &\\approx 2 \\cdot 10^{-8}\n",
    "      ,\n",
    "\\end{align}\n",
    "\n",
    "which meeds we need at least $77712216$ slices using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supporting calculations for above text block\n",
    "needed_h = 1e-8 / np.exp(coeffs[1])\n",
    "needed_n = np.pi / 2 / needed_h\n",
    "\n",
    "print(\"approx h required: %e\" % needed_h)\n",
    "print(\"approx N required: %f\" % needed_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trapezoid rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the lab script we are shown a picture of how the trapezoid rule works. Given $x$ values $\\{x_0, x_1, x_2, x_3\\}$ and corresponding function values $\\{y_0, y_1, y_2, y_3\\}$. There are many ways to compute the sum of the trapezoids: for each trapezoid I will add the the rectangle induced the height of the right endpoint together with the remaining half rectangle. This gives us the formula for the sum $S$ as\n",
    "\n",
    "\\begin{align}\n",
    "    S &= \\sum_{i = 1}^3\n",
    "        \\left(\n",
    "            y_i h\n",
    "            + \\frac{1}{2} \\left( y_{i - 1} - y_i \\right) h\n",
    "        \\right) \\\\\n",
    "      &= h \\sum_{i = 1}^3\n",
    "        \\left(\n",
    "            \\frac{1}{2} \\left( y_{i - 1} + y_i \\right)\n",
    "        \\right)\n",
    "\\end{align}\n",
    "\n",
    "where $h = x_i - x_{i - 1}$ (assumed constant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the trapezoid rule, we will repeat the investigation we performed when using the left Riemann approximation. We will keep the same number of $N$ values to test and the corresponding $h$ values we used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each N value calculate the absolute error\n",
    "errors = np.zeros(num_ns)\n",
    "\n",
    "for idx, n in enumerate(n_vals):\n",
    "    xs = np.linspace(0, np.pi / 2, n + 1)\n",
    "    ys = np.sin(xs)\n",
    "\n",
    "    errors[idx] = abs(1 - integrate.trapz(y=ys, dx=np.pi / (2 * n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.loglog(h_vals, errors, \"o\")\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$h$\")\n",
    "ax.set_ylabel(\"abs error\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the log-log relationship is still linear. However, for the same values of $h$ the error in the trapezoidal rule is much lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll calculate the $A$ and $\\alpha$ parameters and estimate what $h$ and $N$ we would need to keep the absolute error below $10^{-8}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the linear coefficients for the loglog relationship\n",
    "coeffs = np.polyfit(x=np.log(h_vals), y=np.log(errors), deg=1)\n",
    "\n",
    "# Translate to A and h\n",
    "print(\"A = %.2f\" % np.exp(coeffs[1]))\n",
    "print(\"alpha = %.2f\" % coeffs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the greatest h/ least N we can use?\n",
    "needed_h = 1e-8 / np.exp(coeffs[1])\n",
    "needed_n = np.pi / 2 / needed_h\n",
    "\n",
    "print(\"approx h required: %e\" % needed_h)\n",
    "print(\"approx N required: %f\" % needed_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare with the left Riemann approximation, we need $77712216 - 13088578 = 64623638$ less steps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpson's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for Simpson's method we need an *even* number of slices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll plot the errors for different values of $h$. Note that we need to be careful to make sure $N$ is even here, so we'll adjust each $N$ value so that this holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to be a little careful since we want the N values to\n",
    "# be logarithmically space, but we also require that each N is an integer.\n",
    "simps_n_vals = n_vals + n_vals % 2\n",
    "simps_h_vals = np.pi / (2 * n_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each N value calculate the absolute error\n",
    "errors = np.zeros(num_ns)\n",
    "\n",
    "for idx, n in enumerate(simps_n_vals):\n",
    "    xs = np.linspace(0, np.pi / 2, n + 1)\n",
    "    ys = np.sin(xs)\n",
    "\n",
    "    errors[idx] = abs(1 - integrate.simps(y=ys, dx=np.pi / (2 * n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "plt.loglog(simps_h_vals, errors, \"o\")\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(r\"$h$\")\n",
    "ax.set_ylabel(\"abs error\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can clearly see that Simpson's method outperforms both methods we looked at before. We quickly reach the limits of machine precision as we increase $N$. The dependence is still linear, although due to the limits of machine precision, we cannot show the full relationship we would get with exact arithmetic here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If wanted to fit the linear relationship we need to look at the values of $N$ that lead to $h \\approx 10^{-3}$ and higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last h value index to keep\n",
    "last_h_idx = 20\n",
    "\n",
    "# Find the linear coefficients for the loglog relationship\n",
    "coeffs = np.polyfit(\n",
    "    x=np.log(h_vals[: last_h_idx + 1]), y=np.log(errors[: last_h_idx + 1]), deg=1\n",
    ")\n",
    "\n",
    "# Translate to A and h\n",
    "print(\"A = %.2f\" % np.exp(coeffs[1]))\n",
    "print(\"alpha = %.2f\" % coeffs[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we can again determine what is the greatest $H$/least $N$ we need to keep the error under $10^{-8}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the greatest h/ least N we can use?\n",
    "needed_h = 1e-8 / np.exp(coeffs[1])\n",
    "needed_n = np.pi / 2 / needed_h\n",
    "\n",
    "print(\"approx h required: %e\" % needed_h)\n",
    "print(\"approx N required: %f\" % needed_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the $A$ value or by looking that the greatest $N$ required, Simpson's method is about twice as efficient as the trapezoid rule  and about eight times as efficient as the left Riemann sum approximation for this integral."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
